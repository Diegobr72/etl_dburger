## ğŸ“Š Projeto ETL â€“ Fato Vendas (DBurger â€“ Parte II)

Este repositÃ³rio reÃºne a segunda etapa do projeto acadÃªmico desenvolvido para atender Ã  **VendeBem**, cujo objetivo Ã© construir a dimensÃ£o de faixa etÃ¡ria e clientes, unificando na fato Venda em um ambiente Azure, empregando **Azure Data Factory (ADF)** e **Azure SQL Database**.

---

### ğŸ¯ Objetivo
Gerar um pipeline ETL robusto que:

- Calcule a idade dos clientes a partir da data de nascimento.
- Classifique cada cliente em uma faixa etÃ¡ria definida.
- Associe estratÃ©gias comerciais adequadas a cada faixa.
- Carregue os dados transformados em tabelas SQL para posterior anÃ¡lise e segmentaÃ§Ã£o.

---

### ğŸ“ Estrutura do RepositÃ³rio

```plaintext
INSIGHTHUNTERS_ETL_FAIXA_ETARIA/
â”œâ”€â”€ README.md
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ 1_evidencias.pdf       
â”‚   â”œâ”€â”€ 2_evidencias.pdf       
â”‚   â””â”€â”€ 3_evidencias.pdf       
â”œâ”€â”€ data/
â”‚   â””â”€â”€ Cadastro_Faixa_Etaria.xlsx  
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ cria_VendeBem.sql       
â”œâ”€â”€ adf/
â”‚   â””â”€â”€ (pasta do Azure Data Fatory)     
â””â”€â”€ output/         
    â””â”€â”€ INSIGHTHUNTERS_dados_processados.CSV          
```

---

### âš™ï¸ PrÃ©-requisitos

1. **Conta Microsoft Azure** com permissÃ£o para criar e gerenciar:
   - Azure Blob Storage
   - Azure SQL Database
   - Azure Data Factory
2. **Oracle Database** acessÃ­vel via view: `DBURGER.V_DB_CLI_3O_CHECKPOINT` (filtrada por `SG_ESTADO = 'SP'`).
3. **Ferramentas locais**:
   - [Azure CLI](https://docs.microsoft.com/cli/azure/install-azure-cli)
   - [SQL Server Management Studio](https://docs.microsoft.com/sql/ssms/download-sql-server-management-studio-ssms)
   - [Azure Data Factory Tools para Visual Studio ou VS Code](https://learn.microsoft.com/azure/data-factory/quickstart-create-data-factory-portal)

---

### ğŸ› ï¸ ConfiguraÃ§Ã£o e ImplantaÃ§Ã£o

#### 1. Provisionamento de Recursos

1. **Blob Storage**
   - Crie um *Storage Account* e um *Container* nomeado `ainsighthunters_rm<seu_rm>`.
   - FaÃ§a o upload de `data/Cadastro_Faixa_Etaria.xlsx`.

2. **Azure SQL Database**
   - Crie o banco de dados `dbinsighthunters_rm<seu_rm>`.
   - Conecte-se ao servidor e execute `scripts/cria_VendeBem.sql`.

3. **Azure Data Factory**
   - Importe o arquivo `pipelines/ADF_pipeline.json` ao seu Data Factory (menu *Author -> Import*).
   - Atualize conexÃµes vinculadas (*Linked Services*) para apontar ao seu Blob Storage, Oracle e Azure SQL.

#### 2. ExecuÃ§Ã£o do Pipeline

- No portal Azure, acesse o Data Factory e selecione o pipeline **ETL_Faixa_Etaria**.
- Clique em **Trigger -> Trigger Now**.
- Acompanhe as atividades na *Monitor*.

---

### ğŸ”„ Processo ETL Detalhado

1. **IngestÃ£o**
   - Leitura de `Cadastro_Faixa_Etaria.xlsx` no Blob Storage.
   - Leitura da view Oracle filtrada por clientes de SP.

2. **TransformaÃ§Ã£o**
   - CÃ¡lculo de idade: `DATEDIFF(year, DT_NASCIMENTO, GETDATE())`.
   - JunÃ§Ã£o com a tabela de faixas para classificaÃ§Ã£o.
   - AtribuiÃ§Ã£o de colunas derivadas:
     - `ESCOLARIDADE`: definido como *Superior Completo*.
     - `ESTADO_CIVIL`: definido como *Solteiro*.

3. **Carga**
   - GravaÃ§Ã£o na tabela `TB_CLIENTE_FAIXA_ETARIA` no Azure SQL Database.

> **Exemplo de definiÃ§Ã£o da tabela de destino**:
>
> ```sql
> CREATE TABLE TB_CLIENTE_FAIXA_ETARIA (
>     ID_CLIENTE INT PRIMARY KEY,
>     NM_CLIENTE VARCHAR(100),
>     IDADE INT,
>     FAIXA_ETARIA VARCHAR(50),
>     ESTRATEGIA_COMERCIAL VARCHAR(200),
>     ESCOLARIDADE VARCHAR(50),
>     ESTADO_CIVIL VARCHAR(50)
> );
> ```

---

### ğŸ“‚ EntregÃ¡veis e EvidÃªncias

1. **docs/1_evidencias.docx**: Capturas de tela do recurso de Blob Storage.
2. **docs/2_evidencias.docx**: Capturas de tela da criaÃ§Ã£o e estrutura do Azure SQL.
3. **docs/3_evidencias.docx**: Fluxo completo do pipeline ADF e resultados antes e depois da carga.